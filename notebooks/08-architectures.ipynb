{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../src\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.special import softmax\n",
    "import albumentations as A\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.swa_utils import AveragedModel, SWALR, update_bn\n",
    "\n",
    "import pretrainedmodels\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "import config\n",
    "import dataset\n",
    "import engine\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20058, 788)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PSEUDO-LABELED DATA\n",
    "# df = pd.read_csv(\"../input/train.csv\")\n",
    "df = pd.read_csv(\"../input/pl-spinal-ensemble10.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: EXPERIMENT WITH AUGMENTATIONS\n",
    "class EMNISTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, list_IDs, augs=None, label=True):\n",
    "        self.list_IDs = list_IDs\n",
    "        self.label = label\n",
    "        self.images = df[config.PIXEL_COLS].values\n",
    "        self.images = self.images.astype(np.uint8)\n",
    "        self.images = self.images.reshape(-1, config.SIZE, config.SIZE, 1)\n",
    "\n",
    "        if label:\n",
    "            self.digits = df.digit.values\n",
    "\n",
    "        if augs is None:\n",
    "            self.augs = A.Compose([\n",
    "                A.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225],\n",
    "                    max_pixel_value=255.0,\n",
    "                    always_apply=True,),\n",
    "            ])\n",
    "        else:\n",
    "            self.augs = augs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.list_IDs)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        # Get image\n",
    "        index = self.list_IDs[item]\n",
    "        image = self.images[index]\n",
    "        image = np.concatenate([image, image, image], axis=2)\n",
    "\n",
    "        # Augment image\n",
    "        image = self.augs(image=image)[\"image\"]\n",
    "\n",
    "        # Convert to PyTorch tensor\n",
    "        image = torch.tensor(image, dtype=torch.float)\n",
    "        image = image.permute(2, 0, 1)\n",
    "\n",
    "        # Get labels and return\n",
    "        if self.label:\n",
    "            digit = self.digits[index]\n",
    "            digit = torch.tensor(digit, dtype=torch.long)\n",
    "            return image, digit\n",
    "        else:\n",
    "            return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet18(pretrained=None):\n",
    "    model = pretrainedmodels.__dict__[\"resnet18\"](pretrained=pretrained)\n",
    "    in_feats = model.last_linear.in_features\n",
    "    model.last_linear = nn.Linear(in_feats, 10)\n",
    "    return model\n",
    "\n",
    "def ResNet34(pretrained=None):\n",
    "    model = pretrainedmodels.__dict__[\"resnet34\"](pretrained=pretrained)\n",
    "    in_feats = model.last_linear.in_features\n",
    "    model.last_linear = nn.Linear(in_feats, 10)\n",
    "    return model\n",
    "\n",
    "def ResNet50(pretrained=None):\n",
    "    model = pretrainedmodels.__dict__[\"resnet50\"](pretrained=pretrained)\n",
    "    in_feats = model.last_linear.in_features\n",
    "    model.last_linear = nn.Linear(in_feats, 10)\n",
    "    return model\n",
    "\n",
    "def ResNet101(pretrained=None):\n",
    "    model = pretrainedmodels.__dict__[\"resnet101\"](pretrained=pretrained)\n",
    "    in_feats = model.last_linear.in_features\n",
    "    model.last_linear = nn.Linear(in_feats, 10)\n",
    "    return model\n",
    "\n",
    "def ResNet152(pretrained=None):\n",
    "    model = pretrainedmodels.__dict__[\"resnet152\"](pretrained=pretrained)\n",
    "    in_feats = model.last_linear.in_features\n",
    "    model.last_linear = nn.Linear(in_feats, 10)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def swish(x):\n",
    "    return x * x.sigmoid()\n",
    "\n",
    "\n",
    "def drop_connect(x, drop_ratio):\n",
    "    keep_ratio = 1.0 - drop_ratio\n",
    "    mask = torch.empty([x.shape[0], 1, 1, 1], dtype=x.dtype, device=x.device)\n",
    "    mask.bernoulli_(keep_ratio)\n",
    "    x.div_(keep_ratio)\n",
    "    x.mul_(mask)\n",
    "    return x\n",
    "\n",
    "\n",
    "class SE(nn.Module):\n",
    "    '''Squeeze-and-Excitation block with Swish.'''\n",
    "\n",
    "    def __init__(self, in_channels, se_channels):\n",
    "        super(SE, self).__init__()\n",
    "        self.se1 = nn.Conv2d(in_channels, se_channels,\n",
    "                             kernel_size=1, bias=True)\n",
    "        self.se2 = nn.Conv2d(se_channels, in_channels,\n",
    "                             kernel_size=1, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        out = swish(self.se1(out))\n",
    "        out = self.se2(out).sigmoid()\n",
    "        out = x * out\n",
    "        return out\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    '''expansion + depthwise + pointwise + squeeze-excitation'''\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size,\n",
    "                 stride,\n",
    "                 expand_ratio=1,\n",
    "                 se_ratio=0.,\n",
    "                 drop_rate=0.):\n",
    "        super(Block, self).__init__()\n",
    "        self.stride = stride\n",
    "        self.drop_rate = drop_rate\n",
    "        self.expand_ratio = expand_ratio\n",
    "\n",
    "        # Expansion\n",
    "        channels = expand_ratio * in_channels\n",
    "        self.conv1 = nn.Conv2d(in_channels,\n",
    "                               channels,\n",
    "                               kernel_size=1,\n",
    "                               stride=1,\n",
    "                               padding=0,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "\n",
    "        # Depthwise conv\n",
    "        self.conv2 = nn.Conv2d(channels,\n",
    "                               channels,\n",
    "                               kernel_size=kernel_size,\n",
    "                               stride=stride,\n",
    "                               padding=(1 if kernel_size == 3 else 2),\n",
    "                               groups=channels,\n",
    "                               bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(channels)\n",
    "\n",
    "        # SE layers\n",
    "        se_channels = int(in_channels * se_ratio)\n",
    "        self.se = SE(channels, se_channels)\n",
    "\n",
    "        # Output\n",
    "        self.conv3 = nn.Conv2d(channels,\n",
    "                               out_channels,\n",
    "                               kernel_size=1,\n",
    "                               stride=1,\n",
    "                               padding=0,\n",
    "                               bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # Skip connection if in and out shapes are the same (MV-V2 style)\n",
    "        self.has_skip = (stride == 1) and (in_channels == out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x if self.expand_ratio == 1 else swish(self.bn1(self.conv1(x)))\n",
    "        out = swish(self.bn2(self.conv2(out)))\n",
    "        out = self.se(out)\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        if self.has_skip:\n",
    "            if self.training and self.drop_rate > 0:\n",
    "                out = drop_connect(out, self.drop_rate)\n",
    "            out = out + x\n",
    "        return out\n",
    "\n",
    "\n",
    "class EfficientNet(nn.Module):\n",
    "    def __init__(self, cfg, num_classes=10):\n",
    "        super(EfficientNet, self).__init__()\n",
    "        self.cfg = cfg\n",
    "        self.conv1 = nn.Conv2d(3,\n",
    "                               32,\n",
    "                               kernel_size=3,\n",
    "                               stride=1,\n",
    "                               padding=1,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.layers = self._make_layers(in_channels=32)\n",
    "        self.linear = nn.Linear(cfg['out_channels'][-1], num_classes)\n",
    "\n",
    "    def _make_layers(self, in_channels):\n",
    "        layers = []\n",
    "        cfg = [self.cfg[k] for k in ['expansion', 'out_channels', 'num_blocks', 'kernel_size',\n",
    "                                     'stride']]\n",
    "        b = 0\n",
    "        blocks = sum(self.cfg['num_blocks'])\n",
    "        for expansion, out_channels, num_blocks, kernel_size, stride in zip(*cfg):\n",
    "            strides = [stride] + [1] * (num_blocks - 1)\n",
    "            for stride in strides:\n",
    "                drop_rate = self.cfg['drop_connect_rate'] * b / blocks\n",
    "                layers.append(\n",
    "                    Block(in_channels,\n",
    "                          out_channels,\n",
    "                          kernel_size,\n",
    "                          stride,\n",
    "                          expansion,\n",
    "                          se_ratio=0.25,\n",
    "                          drop_rate=drop_rate))\n",
    "                in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.ZeroPad2d(4)(x)\n",
    "        \n",
    "        out = swish(self.bn1(self.conv1(x)))\n",
    "        out = self.layers(out)\n",
    "        out = F.adaptive_avg_pool2d(out, 1)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        dropout_rate = self.cfg['dropout_rate']\n",
    "        if self.training and dropout_rate > 0:\n",
    "            out = F.dropout(out, p=dropout_rate)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def EfficientNetB0():\n",
    "    cfg = {\n",
    "        'num_blocks': [1, 2, 2, 3, 3, 4, 1],\n",
    "        'expansion': [1, 6, 6, 6, 6, 6, 6],\n",
    "        'out_channels': [16, 24, 40, 80, 112, 192, 320],\n",
    "        'kernel_size': [3, 3, 5, 3, 5, 5, 3],\n",
    "        'stride': [1, 2, 2, 2, 1, 2, 1],\n",
    "        'dropout_rate': 0.2,\n",
    "        'drop_connect_rate': 0.2,\n",
    "    }\n",
    "    return EfficientNet(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Wide ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=True)\n",
    "\n",
    "def conv_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        init.xavier_uniform_(m.weight, gain=np.sqrt(2))\n",
    "        init.constant_(m.bias, 0)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        init.constant_(m.weight, 1)\n",
    "        init.constant_(m.bias, 0)\n",
    "\n",
    "class wide_basic(nn.Module):\n",
    "    def __init__(self, in_planes, planes, dropout_rate, stride=1):\n",
    "        super(wide_basic, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, padding=1, bias=True)\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=True)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=True),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.dropout(self.conv1(F.relu(self.bn1(x))))\n",
    "        out = self.conv2(F.relu(self.bn2(out)))\n",
    "        out += self.shortcut(x)\n",
    "\n",
    "        return out\n",
    "\n",
    "class Wide_ResNet(nn.Module):\n",
    "    def __init__(self, depth, widen_factor, dropout_rate, num_classes):\n",
    "        super(Wide_ResNet, self).__init__()\n",
    "        self.in_planes = 16\n",
    "\n",
    "        assert ((depth-4)%6 ==0), 'Wide-resnet depth should be 6n+4'\n",
    "        n = (depth-4)/6\n",
    "        k = widen_factor\n",
    "\n",
    "        print('| Wide-Resnet %dx%d' %(depth, k))\n",
    "        nStages = [16, 16*k, 32*k, 64*k]\n",
    "\n",
    "        # ADD PADDING\n",
    "        self.pad = nn.ZeroPad2d(4)\n",
    "        \n",
    "        self.conv1 = conv3x3(3,nStages[0])\n",
    "        self.layer1 = self._wide_layer(wide_basic, nStages[1], n, dropout_rate, stride=1)\n",
    "        self.layer2 = self._wide_layer(wide_basic, nStages[2], n, dropout_rate, stride=2)\n",
    "        self.layer3 = self._wide_layer(wide_basic, nStages[3], n, dropout_rate, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(nStages[3], momentum=0.9)\n",
    "        self.linear = nn.Linear(nStages[3], num_classes)\n",
    "\n",
    "    def _wide_layer(self, block, planes, num_blocks, dropout_rate, stride):\n",
    "        strides = [stride] + [1]*(int(num_blocks)-1)\n",
    "        layers = []\n",
    "\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, dropout_rate, stride))\n",
    "            self.in_planes = planes\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # ADD PADDING\n",
    "        x = self.pad(x)\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.relu(self.bn1(out))\n",
    "        out = F.avg_pool2d(out, 8)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def DenseNet121(pretrained=None):\n",
    "    model = pretrainedmodels.__dict__[\"densenet121\"](pretrained=pretrained)\n",
    "    in_feats = model.last_linear.in_features\n",
    "    model.last_linear = nn.Linear(in_feats, 10)\n",
    "    return model\n",
    "\n",
    "def DenseNet161(pretrained=None):\n",
    "    model = pretrainedmodels.__dict__[\"densenet161\"](pretrained=pretrained)\n",
    "    in_feats = model.last_linear.in_features\n",
    "    model.last_linear = nn.Linear(in_feats, 10)\n",
    "    model.last_linear = nn.Linear(1024, 10)\n",
    "    return model\n",
    "\n",
    "def DenseNet169(pretrained=None):\n",
    "    model = pretrainedmodels.__dict__[\"densenet169\"](pretrained=pretrained)\n",
    "    in_feats = model.last_linear.in_features\n",
    "    model.last_linear = nn.Linear(in_feats, 10)\n",
    "    return model\n",
    "\n",
    "def DenseNet201(pretrained=None):\n",
    "    model = pretrainedmodels.__dict__[\"densenet201\"](pretrained=pretrained)\n",
    "    in_feats = model.last_linear.in_features\n",
    "    model.last_linear = nn.Linear(in_feats, 10)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###   Model Dispatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_model(model_name, pretrained=None):\n",
    "    if model_name == \"resnet18\":\n",
    "        return ResNet18(pretrained)\n",
    "    elif model_name == \"resnet34\":\n",
    "        return ResNet34(pretrained)\n",
    "    elif model_name == \"resnet50\":\n",
    "        return ResNet50(pretrained)\n",
    "    elif model_name == \"resnet101\":\n",
    "        return ResNet101(pretrained)\n",
    "    elif model_name == \"resnet152\":\n",
    "        return ResNet152(pretrained)\n",
    "    elif model_name == \"wideresnet28x10\":\n",
    "        return Wide_ResNet(28, 10, 0.3, 10)\n",
    "    elif model_name == \"efficientnet\":\n",
    "        return EfficientNetB0()\n",
    "    elif model_name == \"efficientnet-b0\":\n",
    "        model = EfficientNet.from_name(\"efficientnet-b0\", image_size=28, num_classes=10)\n",
    "        model._fc = nn.Linear(1280, 10)\n",
    "        return model\n",
    "    elif model_name == \"efficientnet-b1\":\n",
    "        model = EfficientNet.from_name(\"efficientnet-b1\", image_size=28)\n",
    "        model._fc = nn.Linear(1280, 10)\n",
    "        return model\n",
    "    elif model_name == \"efficientnet-b2\":\n",
    "        model = EfficientNet.from_name(\"efficientnet-b2\", image_size=28)\n",
    "        model._fc = nn.Linear(1408, 10)\n",
    "        return model\n",
    "    elif model_name == \"efficientnet-b3\":\n",
    "        model = EfficientNet.from_name(\"efficientnet-b3\", image_size=28)\n",
    "        model._fc = nn.Linear(1536, 10)\n",
    "        return model\n",
    "    elif model_name == \"efficientnet-b4\":\n",
    "        model = EfficientNet.from_name(\"efficientnet-b4\", image_size=28)\n",
    "        model._fc = nn.Linear(1792, 10)\n",
    "        return model\n",
    "    elif model_name == \"efficientnet-b5\":\n",
    "        model = EfficientNet.from_name(\"efficientnet-b5\", image_size=28)\n",
    "        model._fc = nn.Linear(2048, 10)\n",
    "        return model\n",
    "    elif model_name == \"efficientnet-b6\":\n",
    "        model = EfficientNet.from_name(\"efficientnet-b6\", image_size=28)\n",
    "        model._fc = nn.Linear(2304, 10)\n",
    "        return model\n",
    "    elif model_name == \"efficientnet-b7\":\n",
    "        model = EfficientNet.from_name(\"efficientnet-b7\", image_size=28)\n",
    "        model._fc = nn.Linear(2560, 10)\n",
    "        return model\n",
    "    elif model_name == \"efficientnet-b8\":\n",
    "        model = EfficientNet.from_name(\"efficientnet-b8\", image_size=28)\n",
    "        model._fc = nn.Linear(2816, 10)\n",
    "        return model\n",
    "    elif model_name == \"efficientnet-l2\":\n",
    "        model = EfficientNet.from_name(\"efficientnet-l2\", image_size=28)\n",
    "        model._fc = nn.Linear(5504, 10)\n",
    "        return model\n",
    "    else:\n",
    "        raise RuntimeError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "NUM_FOLDS = 5\n",
    "# EPOCHS = 350\n",
    "# MODEL_NAME = \"efficientnet-b1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Wide ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "oof = np.zeros((len(df), 10))\n",
    "\n",
    "for fold in range(NUM_FOLDS):    \n",
    "    train_indices = np.load(f\"../input/train_idx-fold{fold}\")\n",
    "    valid_indices = np.load(f\"../input/valid_idx-fold{fold}\")\n",
    "    train_ds = EMNISTDataset(df, train_indices)\n",
    "    valid_ds = EMNISTDataset(df, valid_indices)\n",
    "    train_loader = torch.utils.data.DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=4)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_ds, batch_size=512)\n",
    "\n",
    "    model = Wide_ResNet(28, 10, 0.3, 10)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4, nesterov=True)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [60, 120, 160], gamma=0.2)\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    swa_start = 150\n",
    "    swa_model = AveragedModel(model).to(device)\n",
    "    swa_scheduler = SWALR(optimizer, anneal_strategy=\"cos\", anneal_epochs=5, swa_lr=8e-4)\n",
    "    \n",
    "    for epoch in range(200):\n",
    "        engine.train(train_loader, model, optimizer, device, scaler, clip_grad=False)\n",
    "        preds, targs = engine.evaluate(valid_loader, model, device)\n",
    "        \n",
    "        if epoch < swa_start:\n",
    "            scheduler.step()\n",
    "        else:\n",
    "            swa_model.update_parameters(model)\n",
    "            swa_sche\n",
    "\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "        accuracy = metrics.accuracy_score(targs, preds)\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Epoch={epoch}, Accuracy={accuracy:.5f}\")\n",
    "\n",
    "    update_bn(train_loader, swa_model.cpu())\n",
    "    preds, targs = engine.evaluate(valid_loader, swa_model.to(device), device)\n",
    "    oof[valid_indices] = preds\n",
    "    accuracy = metrics.accuracy_score(targs, np.argmax(preds, axis=1))\n",
    "    print(f\"Fold={fold}, Accuracy={accuracy}\")\n",
    "    \n",
    "    torch.save(swa_model.state_dict(), f\"../models/wide_resnet28x10-sgd-200eps-pl-swa-fold{fold}.pt\")\n",
    "\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "               \n",
    "np.save(f\"oof-wide_resnet28x10-swa\", oof)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_indices, valid_indices = model_selection.train_test_split(\n",
    "#     np.arange(len(df)), test_size=0.1, stratify=df.digit\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=0, Accuracy=0.76595\n",
      "Epoch=10, Accuracy=0.90803\n",
      "Epoch=20, Accuracy=0.87039\n",
      "Epoch=30, Accuracy=0.91650\n",
      "Epoch=40, Accuracy=0.90603\n",
      "Epoch=50, Accuracy=0.91725\n",
      "Epoch=60, Accuracy=0.92149\n",
      "Epoch=70, Accuracy=0.91077\n",
      "Epoch=80, Accuracy=0.92173\n",
      "Epoch=90, Accuracy=0.90828\n",
      "Epoch=100, Accuracy=0.91401\n",
      "Epoch=110, Accuracy=0.89806\n",
      "Epoch=120, Accuracy=0.90927\n",
      "Epoch=130, Accuracy=0.89806\n",
      "Epoch=140, Accuracy=0.92448\n",
      "Epoch=150, Accuracy=0.92822\n",
      "Epoch=160, Accuracy=0.93295\n",
      "Epoch=170, Accuracy=0.93096\n",
      "Epoch=180, Accuracy=0.93420\n",
      "Epoch=190, Accuracy=0.93195\n",
      "Epoch=200, Accuracy=0.93270\n",
      "Epoch=210, Accuracy=0.93195\n",
      "Epoch=220, Accuracy=0.93195\n",
      "Epoch=230, Accuracy=0.93170\n",
      "Epoch=240, Accuracy=0.93295\n",
      "Epoch=250, Accuracy=0.93146\n",
      "Epoch=260, Accuracy=0.93245\n",
      "Epoch=270, Accuracy=0.93170\n",
      "Epoch=280, Accuracy=0.93071\n",
      "Epoch=290, Accuracy=0.93121\n",
      "Epoch=300, Accuracy=0.93121\n",
      "Epoch=310, Accuracy=0.93170\n",
      "Epoch=320, Accuracy=0.93096\n",
      "Epoch=330, Accuracy=0.93195\n",
      "Epoch=340, Accuracy=0.93220\n",
      "Fold=0, Accuracy=0.9317048853439681\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"efficientnet\"\n",
    "EPOCHS = 350\n",
    "\n",
    "oof = np.zeros((len(df), 10))\n",
    "\n",
    "for fold in range(NUM_FOLDS):\n",
    "    # DATA\n",
    "    train_indices = np.load(f\"../input/folds/train_idx-train-csv-fold{fold}.npy\")\n",
    "    valid_indices = np.load(f\"../input/folds/valid_idx-train-csv-fold{fold}.npy\")\n",
    "    train_ds = EMNISTDataset(df, train_indices)\n",
    "    valid_ds = EMNISTDataset(df, valid_indices)\n",
    "    train_loader = torch.utils.data.DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=4)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_ds, batch_size=512)\n",
    "    \n",
    "    # MODEL and OPTIMIZER\n",
    "    model = get_model(MODEL_NAME).to(device)\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [150, 250], gamma=0.1)\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    # SWA\n",
    "    swa_start = int(0.75 * EPOCHS)\n",
    "    swa_model = AveragedModel(model).to(device)\n",
    "    swa_scheduler = SWALR(optimizer, anneal_strategy=\"cos\", anneal_epochs=5, swa_lr=1e-3)\n",
    "    \n",
    "    # TRAINING EPOCHS\n",
    "    for epoch in range(EPOCHS):\n",
    "        engine.train(train_loader, model, optimizer, device, scaler, clip_grad=False)\n",
    "        preds, targs = engine.evaluate(valid_loader, model, device)\n",
    "        \n",
    "        if epoch > swa_start:\n",
    "            swa_model.update_parameters(model)\n",
    "            swa_scheduler.step()\n",
    "        else:\n",
    "            scheduler.step()\n",
    "\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "        accuracy = metrics.accuracy_score(targs, preds)\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch={epoch}, Accuracy={accuracy:.5f}\")\n",
    "\n",
    "    # WARMUP BATCH STATISTICS\n",
    "    update_bn(train_loader, swa_model.cpu())\n",
    "    \n",
    "    preds, targs = engine.evaluate(valid_loader, swa_model.to(device), device)\n",
    "    oof[valid_indices] = preds\n",
    "    accuracy = metrics.accuracy_score(targs, np.argmax(preds, axis=1))\n",
    "    print(f\"Fold={fold}, Accuracy={accuracy}\")\n",
    "    \n",
    "    torch.save(swa_model.state_dict(), f\"../models/{MODEL_NAME}-{fold}.pt\")\n",
    "\n",
    "    del model, swa_model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    break\n",
    "\n",
    "np.save(f\"../input/interim/oof-{MODEL_NAME}\", oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=0, Accuracy=0.09372\n",
      "Epoch=10, Accuracy=0.10892\n",
      "Epoch=20, Accuracy=0.35992\n",
      "Epoch=30, Accuracy=0.58001\n",
      "Epoch=40, Accuracy=0.75499\n",
      "Epoch=50, Accuracy=0.68968\n",
      "Epoch=60, Accuracy=0.85394\n",
      "Epoch=70, Accuracy=0.73903\n",
      "Epoch=80, Accuracy=0.84671\n",
      "Epoch=90, Accuracy=0.74377\n",
      "Epoch=100, Accuracy=0.87388\n",
      "Epoch=110, Accuracy=0.75648\n",
      "Epoch=120, Accuracy=0.86291\n",
      "Epoch=130, Accuracy=0.85070\n",
      "Epoch=140, Accuracy=0.79038\n",
      "Epoch=150, Accuracy=0.90803\n",
      "Epoch=160, Accuracy=0.91451\n",
      "Epoch=170, Accuracy=0.91550\n",
      "Epoch=180, Accuracy=0.91650\n",
      "Epoch=190, Accuracy=0.91725\n",
      "Epoch=200, Accuracy=0.91725\n",
      "Epoch=210, Accuracy=0.91226\n",
      "Epoch=220, Accuracy=0.91451\n",
      "Epoch=230, Accuracy=0.91401\n",
      "Epoch=240, Accuracy=0.91401\n",
      "Epoch=250, Accuracy=0.91476\n",
      "Epoch=260, Accuracy=0.91476\n",
      "Epoch=270, Accuracy=0.91451\n",
      "Epoch=280, Accuracy=0.91525\n",
      "Epoch=290, Accuracy=0.91451\n",
      "Epoch=300, Accuracy=0.91500\n",
      "Epoch=310, Accuracy=0.91476\n",
      "Epoch=320, Accuracy=0.91500\n",
      "Epoch=330, Accuracy=0.91451\n",
      "Epoch=340, Accuracy=0.91476\n",
      "Fold=0, Accuracy=0.9142572283150548\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"efficientnet-b0\"\n",
    "EPOCHS = 350\n",
    "\n",
    "oof = np.zeros((len(df), 10))\n",
    "\n",
    "for fold in range(NUM_FOLDS):\n",
    "    # DATA\n",
    "    train_indices = np.load(f\"../input/folds/train_idx-train-csv-fold{fold}.npy\")\n",
    "    valid_indices = np.load(f\"../input/folds/valid_idx-train-csv-fold{fold}.npy\")\n",
    "    train_ds = EMNISTDataset(df, train_indices)\n",
    "    valid_ds = EMNISTDataset(df, valid_indices)\n",
    "    train_loader = torch.utils.data.DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=4)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_ds, batch_size=512)\n",
    "    \n",
    "    # MODEL and OPTIMIZER\n",
    "    model = get_model(MODEL_NAME).to(device)\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [150, 250, 350], gamma=0.1)\n",
    "#     optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
    "#     scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    # SWA\n",
    "    swa_start = int(0.75 * EPOCHS)\n",
    "    swa_model = AveragedModel(model).to(device)\n",
    "    swa_scheduler = SWALR(optimizer, anneal_strategy=\"cos\", anneal_epochs=5, swa_lr=1e-4)\n",
    "    \n",
    "    # TRAINING EPOCHS\n",
    "    for epoch in range(EPOCHS):\n",
    "        engine.train(train_loader, model, optimizer, device, scaler, clip_grad=False)\n",
    "        preds, targs = engine.evaluate(valid_loader, model, device)\n",
    "        \n",
    "        if epoch > swa_start:\n",
    "            swa_model.update_parameters(model)\n",
    "            swa_scheduler.step()\n",
    "        else:\n",
    "            scheduler.step()\n",
    "\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "        accuracy = metrics.accuracy_score(targs, preds)\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch={epoch}, Accuracy={accuracy:.5f}\")\n",
    "\n",
    "    # WARMUP BATCH STATISTICS\n",
    "    update_bn(train_loader, swa_model.cpu())\n",
    "    \n",
    "    preds, targs = engine.evaluate(valid_loader, swa_model.to(device), device)\n",
    "    oof[valid_indices] = preds\n",
    "    accuracy = metrics.accuracy_score(targs, np.argmax(preds, axis=1))\n",
    "    print(f\"Fold={fold}, Accuracy={accuracy}\")\n",
    "    \n",
    "    torch.save(swa_model.state_dict(), f\"../models/{MODEL_NAME}-{fold}.pt\")\n",
    "\n",
    "    del model, swa_model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    break\n",
    "\n",
    "np.save(f\"../input/interim/oof-{MODEL_NAME}\", oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=0, Accuracy=0.10842\n",
      "Epoch=10, Accuracy=0.28689\n",
      "Epoch=20, Accuracy=0.58998\n",
      "Epoch=30, Accuracy=0.74252\n",
      "Epoch=40, Accuracy=0.83674\n",
      "Epoch=50, Accuracy=0.86640\n",
      "Epoch=60, Accuracy=0.84023\n",
      "Epoch=70, Accuracy=0.85444\n",
      "Epoch=80, Accuracy=0.88833\n",
      "Epoch=90, Accuracy=0.87762\n",
      "Epoch=100, Accuracy=0.86366\n",
      "Epoch=110, Accuracy=0.86191\n",
      "Epoch=120, Accuracy=0.87737\n",
      "Epoch=130, Accuracy=0.85120\n",
      "Epoch=140, Accuracy=0.88310\n",
      "Epoch=150, Accuracy=0.90852\n",
      "Epoch=160, Accuracy=0.91127\n",
      "Epoch=170, Accuracy=0.91201\n",
      "Epoch=180, Accuracy=0.91276\n",
      "Epoch=190, Accuracy=0.91451\n",
      "Epoch=200, Accuracy=0.91426\n",
      "Epoch=210, Accuracy=0.91301\n",
      "Epoch=220, Accuracy=0.91152\n",
      "Epoch=230, Accuracy=0.91301\n",
      "Epoch=240, Accuracy=0.91326\n",
      "Epoch=250, Accuracy=0.91201\n",
      "Epoch=260, Accuracy=0.91226\n",
      "Epoch=270, Accuracy=0.91201\n",
      "Epoch=280, Accuracy=0.91201\n",
      "Epoch=290, Accuracy=0.91301\n",
      "Epoch=300, Accuracy=0.91276\n",
      "Epoch=310, Accuracy=0.91276\n",
      "Epoch=320, Accuracy=0.91226\n",
      "Epoch=330, Accuracy=0.91226\n",
      "Epoch=340, Accuracy=0.91276\n",
      "Fold=0, Accuracy=0.9125124626121635\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"efficientnet-b1\"\n",
    "EPOCHS = 350\n",
    "\n",
    "oof = np.zeros((len(df), 10))\n",
    "\n",
    "for fold in range(NUM_FOLDS):\n",
    "    # DATA\n",
    "    train_indices = np.load(f\"../input/folds/train_idx-train-csv-fold{fold}.npy\")\n",
    "    valid_indices = np.load(f\"../input/folds/valid_idx-train-csv-fold{fold}.npy\")\n",
    "    train_ds = EMNISTDataset(df, train_indices)\n",
    "    valid_ds = EMNISTDataset(df, valid_indices)\n",
    "    train_loader = torch.utils.data.DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=4)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_ds, batch_size=512)\n",
    "    \n",
    "    # MODEL and OPTIMIZER\n",
    "    model = get_model(MODEL_NAME).to(device)\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [150, 250, 350], gamma=0.1)\n",
    "#     optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
    "#     scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    # SWA\n",
    "    swa_start = int(0.75 * EPOCHS)\n",
    "    swa_model = AveragedModel(model).to(device)\n",
    "    swa_scheduler = SWALR(optimizer, anneal_strategy=\"cos\", anneal_epochs=5, swa_lr=1e-4)\n",
    "    \n",
    "    # TRAINING EPOCHS\n",
    "    for epoch in range(EPOCHS):\n",
    "        engine.train(train_loader, model, optimizer, device, scaler, clip_grad=False)\n",
    "        preds, targs = engine.evaluate(valid_loader, model, device)\n",
    "        \n",
    "        if epoch > swa_start:\n",
    "            swa_model.update_parameters(model)\n",
    "            swa_scheduler.step()\n",
    "        else:\n",
    "            scheduler.step()\n",
    "\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "        accuracy = metrics.accuracy_score(targs, preds)\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch={epoch}, Accuracy={accuracy:.5f}\")\n",
    "\n",
    "    # WARMUP BATCH STATISTICS\n",
    "    update_bn(train_loader, swa_model.cpu())\n",
    "    \n",
    "    preds, targs = engine.evaluate(valid_loader, swa_model.to(device), device)\n",
    "    oof[valid_indices] = preds\n",
    "    accuracy = metrics.accuracy_score(targs, np.argmax(preds, axis=1))\n",
    "    print(f\"Fold={fold}, Accuracy={accuracy}\")\n",
    "    \n",
    "    torch.save(swa_model.state_dict(), f\"../models/{MODEL_NAME}-{fold}.pt\")\n",
    "\n",
    "    del model, swa_model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    break\n",
    "\n",
    "np.save(f\"../input/interim/oof-{MODEL_NAME}\", oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=0, Accuracy=0.10618\n",
      "Epoch=10, Accuracy=0.09472\n",
      "Epoch=20, Accuracy=0.12263\n",
      "Epoch=30, Accuracy=0.78739\n",
      "Epoch=40, Accuracy=0.82428\n",
      "Epoch=50, Accuracy=0.87836\n",
      "Epoch=60, Accuracy=0.85693\n",
      "Epoch=70, Accuracy=0.81256\n",
      "Epoch=80, Accuracy=0.86590\n",
      "Epoch=90, Accuracy=0.22333\n",
      "Epoch=100, Accuracy=0.81954\n",
      "Epoch=110, Accuracy=0.87014\n",
      "Epoch=120, Accuracy=0.74227\n",
      "Epoch=130, Accuracy=0.84422\n",
      "Epoch=140, Accuracy=0.86266\n",
      "Epoch=150, Accuracy=0.26097\n",
      "Epoch=160, Accuracy=0.85095\n",
      "Epoch=170, Accuracy=0.89083\n",
      "Epoch=180, Accuracy=0.89008\n",
      "Epoch=190, Accuracy=0.87662\n",
      "Epoch=200, Accuracy=0.88111\n",
      "Epoch=210, Accuracy=0.56755\n",
      "Epoch=220, Accuracy=0.90578\n",
      "Epoch=230, Accuracy=0.90204\n",
      "Epoch=240, Accuracy=0.89506\n",
      "Epoch=250, Accuracy=0.90479\n",
      "Epoch=260, Accuracy=0.90204\n",
      "Epoch=270, Accuracy=0.91899\n",
      "Epoch=280, Accuracy=0.91974\n",
      "Epoch=290, Accuracy=0.92074\n",
      "Epoch=300, Accuracy=0.92074\n",
      "Epoch=310, Accuracy=0.91949\n",
      "Epoch=320, Accuracy=0.91974\n",
      "Epoch=330, Accuracy=0.91949\n",
      "Epoch=340, Accuracy=0.91999\n",
      "Fold=0, Accuracy=0.9194915254237288\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"efficientnet-b2\"\n",
    "EPOCHS = 350\n",
    "\n",
    "oof = np.zeros((len(df), 10))\n",
    "\n",
    "for fold in range(NUM_FOLDS):\n",
    "    # DATA\n",
    "    train_indices = np.load(f\"../input/folds/train_idx-train-csv-fold{fold}.npy\")\n",
    "    valid_indices = np.load(f\"../input/folds/valid_idx-train-csv-fold{fold}.npy\")\n",
    "    train_ds = EMNISTDataset(df, train_indices)\n",
    "    valid_ds = EMNISTDataset(df, valid_indices)\n",
    "    train_loader = torch.utils.data.DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=4)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_ds, batch_size=512)\n",
    "    \n",
    "    # MODEL and OPTIMIZER\n",
    "    model = get_model(MODEL_NAME).to(device)\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "#     scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [150, 250, 350], gamma=0.1)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    # SWA\n",
    "    swa_start = int(0.75 * EPOCHS)\n",
    "    swa_model = AveragedModel(model).to(device)\n",
    "    swa_scheduler = SWALR(optimizer, anneal_strategy=\"cos\", anneal_epochs=5, swa_lr=1e-4)\n",
    "    \n",
    "    # TRAINING EPOCHS\n",
    "    for epoch in range(EPOCHS):\n",
    "        engine.train(train_loader, model, optimizer, device, scaler, clip_grad=False)\n",
    "        preds, targs = engine.evaluate(valid_loader, model, device)\n",
    "        \n",
    "        if epoch > swa_start:\n",
    "            swa_model.update_parameters(model)\n",
    "            swa_scheduler.step()\n",
    "        else:\n",
    "            scheduler.step()\n",
    "\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "        accuracy = metrics.accuracy_score(targs, preds)\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch={epoch}, Accuracy={accuracy:.5f}\")\n",
    "\n",
    "    # WARMUP BATCH STATISTICS\n",
    "    update_bn(train_loader, swa_model.cpu())\n",
    "    \n",
    "    preds, targs = engine.evaluate(valid_loader, swa_model.to(device), device)\n",
    "    oof[valid_indices] = preds\n",
    "    accuracy = metrics.accuracy_score(targs, np.argmax(preds, axis=1))\n",
    "    print(f\"Fold={fold}, Accuracy={accuracy}\")\n",
    "    \n",
    "    torch.save(swa_model.state_dict(), f\"../models/{MODEL_NAME}-{fold}.pt\")\n",
    "\n",
    "    del model, swa_model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    break\n",
    "\n",
    "np.save(f\"../input/interim/oof-{MODEL_NAME}\", oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=0, Accuracy=0.09945\n",
      "Epoch=10, Accuracy=0.11316\n",
      "Epoch=20, Accuracy=0.20713\n",
      "Epoch=30, Accuracy=0.45214\n",
      "Epoch=40, Accuracy=0.54487\n",
      "Epoch=50, Accuracy=0.61466\n",
      "Epoch=60, Accuracy=0.67522\n",
      "Epoch=70, Accuracy=0.69093\n",
      "Epoch=80, Accuracy=0.70464\n",
      "Epoch=90, Accuracy=0.70115\n",
      "Epoch=100, Accuracy=0.70713\n",
      "Epoch=110, Accuracy=0.70314\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"efficientnet-b3\"\n",
    "EPOCHS = 200\n",
    "oof = np.zeros((len(df), 10))\n",
    "\n",
    "for fold in range(NUM_FOLDS):\n",
    "    # DATA\n",
    "    train_indices = np.load(f\"../input/folds/train_idx-train-csv-fold{fold}.npy\")\n",
    "    valid_indices = np.load(f\"../input/folds/valid_idx-train-csv-fold{fold}.npy\")\n",
    "    train_ds = EMNISTDataset(df, train_indices)\n",
    "    valid_ds = EMNISTDataset(df, valid_indices)\n",
    "    train_loader = torch.utils.data.DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=4)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_ds, batch_size=512)\n",
    "    \n",
    "    # MODEL and OPTIMIZER\n",
    "    model = get_model(MODEL_NAME).to(device)\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.025, momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30, 60, 120], gamma=0.2)\n",
    "#     scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    # SWA\n",
    "    swa_start = int(0.75 * EPOCHS)\n",
    "    swa_model = AveragedModel(model).to(device)\n",
    "    swa_scheduler = SWALR(optimizer, anneal_strategy=\"cos\", anneal_epochs=5, swa_lr=2.5e-5)\n",
    "    \n",
    "    # TRAINING EPOCHS\n",
    "    for epoch in range(EPOCHS):\n",
    "        engine.train(train_loader, model, optimizer, device, scaler, clip_grad=False)\n",
    "        preds, targs = engine.evaluate(valid_loader, model, device)\n",
    "        \n",
    "        if epoch > swa_start:\n",
    "            swa_model.update_parameters(model)\n",
    "            swa_scheduler.step()\n",
    "        else:\n",
    "            scheduler.step()\n",
    "\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "        accuracy = metrics.accuracy_score(targs, preds)\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch={epoch}, Accuracy={accuracy:.5f}\")\n",
    "\n",
    "    # WARMUP BATCH STATISTICS\n",
    "    update_bn(train_loader, swa_model.cpu())\n",
    "    \n",
    "    preds, targs = engine.evaluate(valid_loader, swa_model.to(device), device)\n",
    "    oof[valid_indices] = preds\n",
    "    accuracy = metrics.accuracy_score(targs, np.argmax(preds, axis=1))\n",
    "    print(f\"Fold={fold}, Accuracy={accuracy}\")\n",
    "    \n",
    "    torch.save(swa_model.state_dict(), f\"../models/{MODEL_NAME}-{fold}.pt\")\n",
    "\n",
    "    del model, swa_model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    break\n",
    "\n",
    "np.save(f\"../input/interim/oof-{MODEL_NAME}\", oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"efficientnet-b7\"\n",
    "\n",
    "oof = np.zeros((len(df), 10))\n",
    "\n",
    "for fold in range(NUM_FOLDS):\n",
    "    # DATA\n",
    "    train_indices = np.load(f\"../input/folds/train_idx-train-csv-fold{fold}.npy\")\n",
    "    valid_indices = np.load(f\"../input/folds/valid_idx-train-csv-fold{fold}.npy\")\n",
    "    train_ds = EMNISTDataset(df, train_indices)\n",
    "    valid_ds = EMNISTDataset(df, valid_indices)\n",
    "    train_loader = torch.utils.data.DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=4)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_ds, batch_size=512)\n",
    "    \n",
    "    # MODEL and OPTIMIZER\n",
    "    model = get_model(MODEL_NAME).to(device)\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.5, momentum=0.9, weight_decay=5e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [150, 250, 350], gamma=0.1)\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    # SWA\n",
    "    swa_start = int(0.75 * EPOCHS)\n",
    "    swa_model = AveragedModel(model).to(device)\n",
    "    swa_scheduler = SWALR(optimizer, anneal_strategy=\"cos\", anneal_epochs=5, swa_lr=1e-4)\n",
    "    \n",
    "    # TRAINING EPOCHS\n",
    "    for epoch in range(EPOCHS):\n",
    "        engine.train(train_loader, model, optimizer, device, scaler, clip_grad=False)\n",
    "        preds, targs = engine.evaluate(valid_loader, model, device)\n",
    "        \n",
    "        if epoch > swa_start:\n",
    "            swa_model.update_parameters(model)\n",
    "            swa_scheduler.step()\n",
    "        else:\n",
    "            scheduler.step()\n",
    "\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "        accuracy = metrics.accuracy_score(targs, preds)\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch={epoch}, Accuracy={accuracy:.5f}\")\n",
    "\n",
    "    # WARMUP BATCH STATISTICS\n",
    "    update_bn(train_loader, swa_model.cpu())\n",
    "    \n",
    "    preds, targs = engine.evaluate(valid_loader, swa_model.to(device), device)\n",
    "    oof[valid_indices] = preds\n",
    "    accuracy = metrics.accuracy_score(targs, np.argmax(preds, axis=1))\n",
    "    print(f\"Fold={fold}, Accuracy={accuracy}\")\n",
    "    \n",
    "    torch.save(swa_model.state_dict(), f\"../models/{MODEL_NAME}-{fold}.pt\")\n",
    "\n",
    "    del model, swa_model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    break\n",
    "\n",
    "np.save(f\"./oof-{MODEL_NAME}\", oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oofb = np.argmax(oof, axis=1)\n",
    "accuracy = metrics.accuracy_score(df.digit.values, oofb)\n",
    "print(f\"CV accuracy score={accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = metrics.confusion_matrix(df.digit, oofb)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(conf, cmap=\"coolwarm\", annot=True, fmt=\"d\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof = np.load(f\"./oof-{MODEL_NAME}.npy\")\n",
    "oof = softmax(oof, axis=1)\n",
    "oofb = np.argmax(oof, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior distribution of digits conditioned on letters\n",
    "dists = joblib.load(\"../input/letter-to-digit-distribution.pkl\")\n",
    "\n",
    "for i, letter in enumerate(df.letter.values):\n",
    "    oof[i] = oof[i] * dists[letter]\n",
    "oofb = np.argmax(oof, axis=1)\n",
    "accuracy = metrics.accuracy_score(df.digit.values, oofb)\n",
    "print(f\"CV accuracy score with Post Process={accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP = -0.9\n",
    "s = pd.Series(oofb)\n",
    "vc = s.value_counts().sort_index()\n",
    "mat = np.diag(vc.astype(\"float32\")**(EXP))\n",
    "\n",
    "oofb = np.argmax(oof.dot(mat), axis=1)\n",
    "accuracy = metrics.accuracy_score(df.digit.values, oofb)\n",
    "print(f\"CV accuracy score with Post Process={accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"../input/test.csv\")\n",
    "test_dataset = EMNISTDataset(df_test, np.arange(len(df_test)), label=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_blend = np.zeros((len(df_test), 10))\n",
    "\n",
    "for fold in range(5):\n",
    "    model = get_model(MODEL_NAME)\n",
    "    model = AveragedModel(model).to(device)\n",
    "    model.load_state_dict(torch.load(f\"../models/{MODEL_NAME}-{fold}.pt\"))\n",
    "    preds = engine.evaluate(test_loader, model, device, target=False)\n",
    "    preds_blend += preds\n",
    "    \n",
    "np.save(f\"./test-preds-{MODEL_NAME}\", preds_blend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POST-PROCESSING\n",
    "# COULD SKIP\n",
    "preds_blendb = np.argmax(preds_blend, axis=1)\n",
    "s = pd.Series(preds_blend)\n",
    "vc = s.value_counts().sort_index()\n",
    "mat = np.diag(vc.astype(\"float32\")**(EXP))\n",
    "preds_blend = preds_blend.dot(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predsb = np.argmax(preds_blend, axis=1)\n",
    "subm = pd.DataFrame({\"id\": df_test.id, \"digit\": predsb})\n",
    "subm.to_csv(f\"../output/{MODEL_NAME}-sgd-450eps-pl-swa-blend.csv\", index=False)\n",
    "subm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_vote = np.zeros((5, len(df_test), 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml] *",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
